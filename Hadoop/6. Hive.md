**Hive (Data Access and Querying in Hadoop Ecosystem)**

**Definition:**
Apache Hive is a data warehouse software project built on top of Apache Hadoop for providing data query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop. Instead of writing complex MapReduce programs, users can write Hive Query Language (HQL) statements, which Hive compiles into MapReduce jobs automatically.

---

**Basic Hive Commands with Example Outputs:**

1. **Start Hive CLI**
```bash
hive
```
**Output:**
```
Hive>
```

2. **Create a Database**
```sql
CREATE DATABASE company_db;
```
**Output:**
```
OK
Time taken: 0.451 seconds
```

3. **List All Databases**
```sql
SHOW DATABASES;
```
**Output:**
```
company_db
default
```

4. **Use a Database**
```sql
USE company_db;
```
**Output:**
```
OK
```

5. **Create a Table**
```sql
CREATE TABLE employees (id INT, name STRING, salary FLOAT) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE;
```
**Output:**
```
OK
Time taken: 0.845 seconds
```

6. **Show Tables**
```sql
SHOW TABLES;
```
**Output:**
```
employees
```

7. **Describe Table**
```sql
DESCRIBE employees;
```
**Output:**
```
id         int
name       string
salary     float
```

8. **Load Data into Table**
```sql
LOAD DATA LOCAL INPATH '/home/hadoop/employees.csv' INTO TABLE employees;
```
**Output:**
```
Loading data to table company_db.employees
OK
```

9. **Query Data from Table**
```sql
SELECT * FROM employees;
```
**Output:**
```
1    John    55000.0
2    Mary    62000.0
3    Steve   70000.0
```

10. **Insert Data into Table**
```sql
INSERT INTO TABLE employees VALUES (4, 'Robert', 80000);
```
**Output:**
```
OK
```

11. **Alter Table to Add a Column**
```sql
ALTER TABLE employees ADD COLUMNS (department STRING);
```
**Output:**
```
OK
```

12. **Drop a Table**
```sql
DROP TABLE employees;
```
**Output:**
```
OK
```

13. **Drop a Database**
```sql
DROP DATABASE company_db CASCADE;
```
**Output:**
```
OK
```

---

**Summary:**
Hive simplifies querying large datasets on Hadoop using SQL-like queries, making it easier for users who are familiar with SQL to perform ETL, analytics, and reporting tasks without needing deep Java or MapReduce knowledge.

